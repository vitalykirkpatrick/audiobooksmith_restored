import json
from pathlib import Path
from typing import List, Dict, Any, Optional

# --- Configuration Constants ---
# Input from Phase 2
INPUT_DATA_FILE = Path("/opt/audiobooksmith/data/unified_narration_data.json")
# Output for Phase 4 (The Chapter Rewriter will read this)
OUTPUT_PROMPT_FILE = Path("/home/ubuntu/audiobooksmith_project/data/prompts/narration_prompts.json")
# Assumed paths for style guides (These files do not exist yet, but the logic must account for them)
GUIDE_PATHS = [
    Path("/home/ubuntu/audiobooksmith_project/guides/core_style_guide.md"),
    Path("/home/ubuntu/audiobooksmith_project/guides/acx_compliance.txt"),
]

# Ensure output directory exists
OUTPUT_PROMPT_FILE.parent.mkdir(parents=True, exist_ok=True)

# --- Type Aliases for Clarity ---
UnifiedData = Dict[str, List[Dict[str, Any]]]
PromptStructure = Dict[str, Any]

def load_unified_data(path: Path) -> Optional[UnifiedData]:
    """
    Loads the unified data structure generated by Phase 2.
    """
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"[ERROR] Unified data file not found at {path}. Run Phase 2 first.")
        return None
    except Exception as e:
        print(f"[ERROR] Failed to load unified data from {path}: {e}")
        return None

def load_guide_content(guide_paths: List[Path]) -> str:
    """
    Loads and concatenates content from all project style guides.
    """
    combined_content = ""
    for path in guide_paths:
        try:
            with open(path, 'r', encoding='utf-8') as f:
                combined_content += f.read() + "\n\n---\n\n"
        except FileNotFoundError:
            # This is expected as we haven't created the guides yet.
            combined_content += f"[WARNING] Guide file not found: {path.name}\n\n---\n\n"
        except Exception as e:
            print(f"[ERROR] Failed to read guide file {path}: {e}")
            
    return combined_content.strip()

def generate_system_prompt(guide_content: str) -> str:
    """
    Generates the static, rule-setting System Prompt.
    """
    system_prompt = (
        "You are an expert Narration Preparation Editor, specializing in converting raw book text "
        "into a final, narration-ready script compliant with Audible/ACX standards. "
        "Your primary goal is to ensure the text is perfectly readable and pronounceable by a human narrator. "
        "Follow these core project guidelines:\n\n"
        f"--- CORE PROJECT GUIDELINES ---\n{guide_content}"
    )
    return system_prompt

def generate_category_prompts(unified_data: UnifiedData) -> Dict[str, str]:
    """
    Generates dynamic, rule-based prompts for each data category.
    """
    category_prompts: Dict[str, str] = {}
    
    # --- Names Pronunciation Prompt ---
    if unified_data.get("names"):
        # We need to assume a 'phonetic_english' field exists, even if it's not in the dummy data
        name_rules = "\n".join([
            f"- Term: {item.get('term')}. Context: {item.get('context', 'N/A')}. Narration Rule: [PHONETIC RULE HERE]"
            for item in unified_data["names"]
        ])
        category_prompts["names_pronunciation"] = (
            "Apply the following specific pronunciation rules for names. "
            "The Chapter Rewriter MUST ensure all names are spelled consistently and any necessary phonetic guidance is added:\n\n"
            f"{name_rules}"
        )

    # --- Units/Cultural Terms Prompt (Aggregated as 'Items' in the dummy manifest) ---
    items = unified_data.get("items")
    if items:
        item_rules = "\n".join([
            f"- Original: {item.get('original', item.get('term'))}. Narration Rule: {item.get('narration_rule', item.get('definition'))}"
            for item in items
        ])
        category_prompts["units_and_cultural_terms"] = (
            "Apply the following conversion and context rules for units of measure and cultural terms. "
            "The goal is to provide the narrator with the converted value or context for clarity:\n\n"
            f"{item_rules}"
        )
        
    # Placeholder for other categories (Places, Currency, Abbreviations)
    category_prompts["places_context"] = "Rule: Ensure all place names are spelled consistently with the manifest."
    
    return category_prompts

def save_prompts(prompts: PromptStructure, output_path: Path) -> None:
    """
    Saves the final prompt structure to the specified output file.
    """
    try:
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(prompts, f, indent=2, ensure_ascii=False)
        print(f"\n[SUCCESS] Prompts saved to: {output_path}")
    except Exception as e:
        print(f"\n[ERROR] Failed to save prompts: {e}")

def main():
    """
    Orchestrates the Guide-Based Prompt Generator process (Phase 3).
    """
    print("--- Phase 3: Guide-Based Prompt Generator ---")
    
    # 1. Load data and guides
    unified_data = load_unified_data(INPUT_DATA_FILE)
    if not unified_data:
        print("[FATAL] Could not load unified data. Exiting.")
        return
        
    guide_content = load_guide_content(GUIDE_PATHS)
    
    # 2. Generate prompts
    system_prompt = generate_system_prompt(guide_content)
    category_prompts = generate_category_prompts(unified_data)
    
    # 3. Assemble final structure
    final_prompts: PromptStructure = {
        "system_prompt": system_prompt,
        "category_prompts": category_prompts,
        "metadata": {
            "source_data_file": str(INPUT_DATA_FILE),
            "guide_files": [str(p) for p in GUIDE_PATHS],
            "timestamp": Path(__file__).stat().st_mtime if Path(__file__).exists() else "N/A"
        }
    }
    
    # 4. Save final structure
    save_prompts(final_prompts, OUTPUT_PROMPT_FILE)

if __name__ == "__main__":
    main()
